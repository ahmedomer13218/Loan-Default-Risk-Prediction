{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up PySpark"
      ],
      "metadata": {
        "id": "zmQ6MfZLApvW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkFWDl6AysmT",
        "outputId": "b7f5879f-26dc-4077-edf0-04ae4aa8dc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "aZlRk9950rH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf"
      ],
      "metadata": {
        "id": "39lD5twf0xS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .appName(\"Classification\")\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "fP3gEZHo0zDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from Drive"
      ],
      "metadata": {
        "id": "e4SL8_HKA4AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acVdIjW_02Rt",
        "outputId": "305803cd-ce43-410a-a99b-c83f36ae9ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "current_dir = '/content/drive/MyDrive'\n",
        "data_relative_path = 'Data'\n",
        "\n",
        "df = spark.read.csv(os.path.join(current_dir, data_relative_path, \"featureSelected_encoded_merged_application.csv\"), header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "gRGeIpPJs9Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data (with manual stratification)"
      ],
      "metadata": {
        "id": "3grtY3IKsnIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=42\n",
        "class_0 = df.filter(F.col(\"TARGET\") == 0)\n",
        "class_1 = df.filter(F.col(\"TARGET\") == 1)\n",
        "\n",
        "class_0_train, class_0_val, class_0_test = class_0.randomSplit([0.7, 0.1, 0.2], seed=seed)\n",
        "\n",
        "class_1_train, class_1_val, class_1_test = class_1.randomSplit([0.7, 0.1, 0.2], seed=seed)\n",
        "\n",
        "train_df = class_0_train.union(class_1_train)\n",
        "val_df = class_0_val.union(class_1_val)\n",
        "test_df = class_0_test.union(class_1_test)"
      ],
      "metadata": {
        "id": "ZVO2DcPZ4Cjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.orderBy(F.rand(seed))\n",
        "val_df = val_df.orderBy(F.rand(seed))\n",
        "test_df = test_df.orderBy(F.rand(seed))"
      ],
      "metadata": {
        "id": "U2rxv63J5eK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((train_df.count(), len(train_df.columns)))\n",
        "print((val_df.count(), len(val_df.columns)))\n",
        "print((test_df.count(), len(test_df.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRoMh4AT4Jhx",
        "outputId": "d691ef95-4973-4b1a-f45d-074f26d47023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(162700, 65)\n",
            "(23077, 65)\n",
            "(46419, 65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the data is splited with correct stratification cz(data is biased)"
      ],
      "metadata": {
        "id": "Vm_pQeLYDB21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = train_df.count()\n",
        "\n",
        "value_counts = train_df.groupBy(\"TARGET\").count()\n",
        "\n",
        "percentage_counts = value_counts.withColumn('percentage', (F.col('count') / total_count) * 100)\n",
        "\n",
        "percentage_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOe0-84h4oKS",
        "outputId": "b20c820e-fcd8-4a3b-9b62-3ecb2a7734b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-----------------+\n",
            "|TARGET| count|       percentage|\n",
            "+------+------+-----------------+\n",
            "|     0|149769|92.05224339274739|\n",
            "|     1| 12931|7.947756607252613|\n",
            "+------+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = val_df.count()\n",
        "\n",
        "value_counts = val_df.groupBy(\"TARGET\").count()\n",
        "\n",
        "percentage_counts = value_counts.withColumn('percentage', (F.col('count') / total_count) * 100)\n",
        "\n",
        "percentage_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-12wg9g4zw5",
        "outputId": "9cf0c30e-3ca2-4b0a-83c9-31f9aed3b886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----------------+\n",
            "|TARGET|count|       percentage|\n",
            "+------+-----+-----------------+\n",
            "|     0|21276| 92.1956926810244|\n",
            "|     1| 1801|7.804307318975604|\n",
            "+------+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_count = test_df.count()\n",
        "\n",
        "value_counts = test_df.groupBy(\"TARGET\").count()\n",
        "\n",
        "percentage_counts = value_counts.withColumn('percentage', (F.col('count') / total_count) * 100)\n",
        "\n",
        "percentage_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW2hSTs944md",
        "outputId": "bc8abad2-8f3e-4e35-eae1-5674fc85d557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+------------------+\n",
            "|TARGET|count|        percentage|\n",
            "+------+-----+------------------+\n",
            "|     0|42855| 92.32210948103148|\n",
            "|     1| 3564|7.6778905189685265|\n",
            "+------+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'TARGET'\n",
        "\n",
        "# For train_df\n",
        "X_train = train_df.drop(target_column)\n",
        "y_train = train_df.select(target_column)\n",
        "\n",
        "# For val_df\n",
        "X_val = val_df.drop(target_column)\n",
        "y_val = val_df.select(target_column)\n",
        "\n",
        "# For test_df\n",
        "X_test = test_df.drop(target_column)\n",
        "y_test = test_df.select(target_column)"
      ],
      "metadata": {
        "id": "NawT6abc5hlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "2-vwKmqB6ehj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "VeGm6fWP56cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVyVvAUSB18Q",
        "outputId": "c1dcd920-a9ac-4ef5-b9a3-7d32c2f4f34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns=[col for col in train_df.columns]"
      ],
      "metadata": {
        "id": "irYx95d-CHxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns.remove(\"TARGET\")"
      ],
      "metadata": {
        "id": "mwTjvwFkCOP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "\n",
        "\n",
        "X_train = assembler.transform(train_df)\n",
        "X_val = assembler.transform(val_df)\n",
        "X_test = assembler.transform(test_df)"
      ],
      "metadata": {
        "id": "rQ8bS8jE6jve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"TARGET\")\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", metricName=\"accuracy\")\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", metricName=\"f1\")"
      ],
      "metadata": {
        "id": "qsR3PyplAP52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. RandomForest Classifier"
      ],
      "metadata": {
        "id": "AxKPzPwsDWC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"TARGET\", seed=42)\n",
        "rf_model = rf.fit(X_train)\n",
        "\n",
        "rf_train_predictions = rf_model.transform(X_train)\n",
        "rf_val_predictions = rf_model.transform(X_val)\n",
        "rf_test_predictions = rf_model.transform(X_test)"
      ],
      "metadata": {
        "id": "vKays8V0AXfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_train_auc = binary_evaluator.evaluate(rf_train_predictions)\n",
        "rf_val_auc = binary_evaluator.evaluate(rf_val_predictions)\n",
        "rf_test_auc = binary_evaluator.evaluate(rf_test_predictions)"
      ],
      "metadata": {
        "id": "8F_LBLMfBrBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_train_accuracy = accuracy_evaluator.evaluate(rf_train_predictions)\n",
        "rf_val_accuracy = accuracy_evaluator.evaluate(rf_val_predictions)\n",
        "rf_test_accuracy = accuracy_evaluator.evaluate(rf_test_predictions)"
      ],
      "metadata": {
        "id": "vR46kzKzC910"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_train_f1 = f1_evaluator.evaluate(rf_train_predictions)\n",
        "rf_val_f1 = f1_evaluator.evaluate(rf_val_predictions)\n",
        "rf_test_f1 = f1_evaluator.evaluate(rf_test_predictions)"
      ],
      "metadata": {
        "id": "qZ3jShUEFqJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"RandomForest AUC - Train: {rf_train_auc}, Validation: {rf_val_auc}, Test: {rf_test_auc}\")\n",
        "print(f\"RandomForest Accuracy - Train: {rf_train_accuracy}, Validation: {rf_val_accuracy}, Test: {rf_test_accuracy}\")\n",
        "print(f\"RandomForest F1 Score - Train: {rf_train_f1}, Validation: {rf_val_f1}, Test: {rf_test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f14d1B2ODB4U",
        "outputId": "8b8857a8-fb34-4987-d1a1-426bedca625d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest AUC - Train: 0.6565381114570914, Validation: 0.6476129960178587, Test: 0.6468449418542753\n",
            "RandomForest Accuracy - Train: 0.9205224339274739, Validation: 0.921956926810244, Test: 0.9232210948103148\n",
            "RandomForest F1 Score - Train: 0.882428173078826, Validation: 0.8845199005620704, Test: 0.8863642273919851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Gradient Boosting Classifier (GBT)"
      ],
      "metadata": {
        "id": "xXJCyuD8De2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"TARGET\", seed=42)\n",
        "gbt_model = gbt.fit(X_train)\n",
        "\n",
        "gbt_train_predictions = gbt_model.transform(X_train)\n",
        "gbt_val_predictions = gbt_model.transform(X_val)\n",
        "gbt_test_predictions = gbt_model.transform(X_test)\n",
        "\n",
        "\n",
        "gbt_train_auc = binary_evaluator.evaluate(gbt_train_predictions)\n",
        "gbt_val_auc = binary_evaluator.evaluate(gbt_val_predictions)\n",
        "gbt_test_auc = binary_evaluator.evaluate(gbt_test_predictions)\n",
        "\n",
        "\n",
        "gbt_train_accuracy = accuracy_evaluator.evaluate(gbt_train_predictions)\n",
        "gbt_val_accuracy = accuracy_evaluator.evaluate(gbt_val_predictions)\n",
        "gbt_test_accuracy = accuracy_evaluator.evaluate(gbt_test_predictions)\n",
        "\n",
        "\n",
        "gbt_train_f1 = f1_evaluator.evaluate(gbt_train_predictions)\n",
        "gbt_val_f1 = f1_evaluator.evaluate(gbt_val_predictions)\n",
        "gbt_test_f1 = f1_evaluator.evaluate(gbt_test_predictions)\n",
        "\n",
        "print(f\"Gradient Boosting AUC - Train: {gbt_train_auc}, Validation: {gbt_val_auc}, Test: {gbt_test_auc}\")\n",
        "print(f\"Gradient Boosting Accuracy - Train: {gbt_train_accuracy}, Validation: {gbt_val_accuracy}, Test: {gbt_test_accuracy}\")\n",
        "print(f\"Gradient Boosting F1 Score - Train: {gbt_train_f1}, Validation: {gbt_val_f1}, Test: {gbt_test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_JQ6qILEw7g",
        "outputId": "3c82accc-4c0e-4d54-bef1-d3c53d5eb448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting AUC - Train: 0.7073215529220184, Validation: 0.6771473990499939, Test: 0.6761514600234316\n",
            "Gradient Boosting Accuracy - Train: 0.9205777504609711, Validation: 0.9219135936213546, Test: 0.923199551907624\n",
            "Gradient Boosting F1 Score - Train: 0.8825761677401183, Validation: 0.8844982692049035, Test: 0.8863534729873809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Decision Tree Classifier"
      ],
      "metadata": {
        "id": "VEILmv8xDk7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"TARGET\", seed=42)\n",
        "dt_model = dt.fit(X_train)\n",
        "\n",
        "dt_train_predictions = dt_model.transform(X_train)\n",
        "dt_val_predictions = dt_model.transform(X_val)\n",
        "dt_test_predictions = dt_model.transform(X_test)\n",
        "\n",
        "dt_train_auc = binary_evaluator.evaluate(dt_train_predictions)\n",
        "dt_val_auc = binary_evaluator.evaluate(dt_val_predictions)\n",
        "dt_test_auc = binary_evaluator.evaluate(dt_test_predictions)\n",
        "\n",
        "dt_train_accuracy = accuracy_evaluator.evaluate(dt_train_predictions)\n",
        "dt_val_accuracy = accuracy_evaluator.evaluate(dt_val_predictions)\n",
        "dt_test_accuracy = accuracy_evaluator.evaluate(dt_test_predictions)\n",
        "\n",
        "dt_train_f1 = f1_evaluator.evaluate(dt_train_predictions)\n",
        "dt_val_f1 = f1_evaluator.evaluate(dt_val_predictions)\n",
        "dt_test_f1 = f1_evaluator.evaluate(dt_test_predictions)\n",
        "\n",
        "print(f\"Decision Tree AUC - Train: {dt_train_auc}, Validation: {dt_val_auc}, Test: {dt_test_auc}\")\n",
        "print(f\"Decision Tree Accuracy - Train: {dt_train_accuracy}, Validation: {dt_val_accuracy}, Test: {dt_test_accuracy}\")\n",
        "print(f\"Decision Tree F1 Score - Train: {dt_train_f1}, Validation: {dt_val_f1}, Test: {dt_test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkrfelf8E8_y",
        "outputId": "a3a89efd-ad46-411a-9013-f70c3e8c71e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree AUC - Train: 0.4504909005748263, Validation: 0.44214254129043434, Test: 0.45441470539669887\n",
            "Decision Tree Accuracy - Train: 0.9205593116164721, Validation: 0.921956926810244, Test: 0.923199551907624\n",
            "Decision Tree F1 Score - Train: 0.8825549170153326, Validation: 0.8845199005620704, Test: 0.8863534729873809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. XGBoost Classifier"
      ],
      "metadata": {
        "id": "eztZK_58Dr6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost.spark import SparkXGBClassifier"
      ],
      "metadata": {
        "id": "0SZWdsQbslr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = SparkXGBClassifier(\n",
        "    features_col=\"features\",\n",
        "    label_col=\"TARGET\",\n",
        "    prediction_col=\"prediction\",\n",
        "    probability_col=\"probability\",\n",
        "    raw_prediction_col=\"rawPrediction\",\n",
        "    missing=0.0,\n",
        "    max_depth=6,\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "ye9fvvAYs6PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr8fq20Xs9kV",
        "outputId": "cd79d7eb-f964-4365-812d-edc58f02502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 1 workers with\n",
            "\tbooster params: {'objective': 'binary:logistic', 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'seed': 42, 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': 0.0}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_preds = xgb_model.transform(X_train)\n",
        "val_preds = xgb_model.transform(X_val)\n",
        "test_preds = xgb_model.transform(X_test)"
      ],
      "metadata": {
        "id": "FsCozMues_hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc = binary_evaluator.evaluate(train_preds)\n",
        "val_auc = binary_evaluator.evaluate(val_preds)\n",
        "test_auc = binary_evaluator.evaluate(test_preds)\n",
        "\n",
        "train_accuracy = accuracy_evaluator.evaluate(train_preds)\n",
        "val_accuracy = accuracy_evaluator.evaluate(val_preds)\n",
        "test_accuracy = accuracy_evaluator.evaluate(test_preds)\n",
        "\n",
        "train_f1 = f1_evaluator.evaluate(train_preds)\n",
        "val_f1 = f1_evaluator.evaluate(val_preds)\n",
        "test_f1 = f1_evaluator.evaluate(test_preds)\n",
        "\n",
        "# Results\n",
        "print(f\"XGBoost AUC - Train: {train_auc:.4f}, Validation: {val_auc:.4f}, Test: {test_auc:.4f}\")\n",
        "print(f\"XGBoost Accuracy - Train: {train_accuracy:.4f}, Validation: {val_accuracy:.4f}, Test: {test_accuracy:.4f}\")\n",
        "print(f\"XGBoost F1 Score - Train: {train_f1:.4f}, Validation: {val_f1:.4f}, Test: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98vWhaQZtNKw",
        "outputId": "77958d1f-9c39-40e5-906c-824672b08259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost AUC - Train: 0.5033, Validation: 0.5010, Test: 0.5010\n",
            "XGBoost Accuracy - Train: 0.9210, Validation: 0.9220, Test: 0.9232\n",
            "XGBoost F1 Score - Train: 0.8837, Validation: 0.8849, Test: 0.8867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non_tree based model (LogisticRegression Classifier)"
      ],
      "metadata": {
        "id": "DxKn2amCtyH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "orRoCL9ltXxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"TARGET\", predictionCol=\"prediction\", probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\", maxIter=100, regParam=0.01)\n",
        "\n",
        "lr_model = lr.fit(X_train)\n",
        "\n",
        "lr_train_preds = lr_model.transform(X_train)\n",
        "lr_val_preds = lr_model.transform(X_val)\n",
        "lr_test_preds = lr_model.transform(X_test)\n",
        "\n",
        "binary_evaluator = BinaryClassificationEvaluator(labelCol=\"TARGET\", rawPredictionCol=\"probability\")\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "train_auc = binary_evaluator.evaluate(lr_train_preds)\n",
        "val_auc = binary_evaluator.evaluate(lr_val_preds)\n",
        "test_auc = binary_evaluator.evaluate(lr_test_preds)\n",
        "\n",
        "train_accuracy = accuracy_evaluator.evaluate(lr_train_preds)\n",
        "val_accuracy = accuracy_evaluator.evaluate(lr_val_preds)\n",
        "test_accuracy = accuracy_evaluator.evaluate(lr_test_preds)\n",
        "\n",
        "train_f1 = f1_evaluator.evaluate(lr_train_preds)\n",
        "val_f1 = f1_evaluator.evaluate(lr_val_preds)\n",
        "test_f1 = f1_evaluator.evaluate(lr_test_preds)\n",
        "\n",
        "# Results\n",
        "print(f\"Logistic Regression AUC - Train: {train_auc:.4f}, Validation: {val_auc:.4f}, Test: {test_auc:.4f}\")\n",
        "print(f\"Logistic Regression Accuracy - Train: {train_accuracy:.4f}, Validation: {val_accuracy:.4f}, Test: {test_accuracy:.4f}\")\n",
        "print(f\"Logistic Regression F1 Score - Train: {train_f1:.4f}, Validation: {val_f1:.4f}, Test: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAsYfsv-t3NF",
        "outputId": "1f78867b-48ac-4aef-d176-6cbbdeb1fd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression AUC - Train: 0.6942, Validation: 0.6905, Test: 0.6859\n",
            "Logistic Regression Accuracy - Train: 0.9204, Validation: 0.9219, Test: 0.9231\n",
            "Logistic Regression F1 Score - Train: 0.8826, Validation: 0.8848, Test: 0.8865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmWpa_sVt_BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K_Fold Cross Validation"
      ],
      "metadata": {
        "id": "GI_iUZt5vzjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## join train & validation"
      ],
      "metadata": {
        "id": "y7zDsgEpEB3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_data = X_train.union(X_val)"
      ],
      "metadata": {
        "id": "5aIKzVRhwOmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K_Fold CV on XGBClassifier to tune some hyperParm's"
      ],
      "metadata": {
        "id": "VplsJYx1EJyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "metadata": {
        "id": "W-roC2nQv3ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = SparkXGBClassifier(\n",
        "    features_col=\"features\",\n",
        "    label_col=\"TARGET\",\n",
        "    device=\"cpu\",\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"TARGET\", metricName=\"f1\")\n",
        "\n",
        "paramGrid = (ParamGridBuilder()\n",
        "    .addGrid(xgb.max_depth, [6, 10])\n",
        "    .addGrid(xgb.learning_rate, [0.1, 0.3])\n",
        "    .addGrid(xgb.n_estimators, [100,200])\n",
        "    .build())\n",
        "\n",
        "\n",
        "crossval = CrossValidator(\n",
        "    estimator=xgb,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3,\n",
        "    parallelism=2\n",
        ")"
      ],
      "metadata": {
        "id": "kd_wV3trxFLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_model = crossval.fit(train_val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTdr9-QUyaeB",
        "outputId": "d391b39a-b7d5-4f03-e4fd-a7ded91bc93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 6, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n",
            "INFO:XGBoost-PySpark:Running xgboost-2.1.4 on 2 workers with\n",
            "\tbooster params: {'device': 'cpu', 'learning_rate': 0.3, 'max_depth': 10, 'objective': 'binary:logistic', 'nthread': 1}\n",
            "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
            "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
            "INFO:XGBoost-PySpark:Finished xgboost training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### try the best model"
      ],
      "metadata": {
        "id": "IXYj-dnkEXoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = cv_model.bestModel\n",
        "\n",
        "best_params = best_model.extractParamMap()\n",
        "\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param.name} = {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qHWmfwXyuFE",
        "outputId": "0b1fac55-cb6d-4b93-fc2d-280631789251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enable_sparse_data_optim = False\n",
            "featuresCol = features\n",
            "features_cols = []\n",
            "labelCol = TARGET\n",
            "predictionCol = prediction\n",
            "probabilityCol = probability\n",
            "rawPredictionCol = rawPrediction\n",
            "arbitrary_params_dict = {}\n",
            "base_score = None\n",
            "booster = None\n",
            "callbacks = None\n",
            "colsample_bylevel = None\n",
            "colsample_bynode = None\n",
            "colsample_bytree = None\n",
            "device = cpu\n",
            "early_stopping_rounds = None\n",
            "eval_metric = None\n",
            "feature_names = None\n",
            "feature_types = None\n",
            "feature_weights = None\n",
            "force_repartition = False\n",
            "gamma = None\n",
            "grow_policy = None\n",
            "importance_type = None\n",
            "interaction_constraints = None\n",
            "iteration_range = None\n",
            "learning_rate = 0.3\n",
            "max_bin = None\n",
            "max_cat_threshold = None\n",
            "max_cat_to_onehot = None\n",
            "max_delta_step = None\n",
            "max_depth = 10\n",
            "max_leaves = None\n",
            "min_child_weight = None\n",
            "missing = nan\n",
            "monotone_constraints = None\n",
            "multi_strategy = None\n",
            "n_estimators = 200\n",
            "num_parallel_tree = None\n",
            "num_workers = 2\n",
            "objective = None\n",
            "random_state = None\n",
            "reg_alpha = None\n",
            "reg_lambda = None\n",
            "repartition_random_shuffle = False\n",
            "sampling_method = None\n",
            "scale_pos_weight = None\n",
            "subsample = None\n",
            "tree_method = None\n",
            "use_gpu = False\n",
            "validate_parameters = None\n",
            "verbose = True\n",
            "verbosity = None\n",
            "xgb_model = None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_predictions = best_model.transform(train_val_data)\n",
        "test_predictions = best_model.transform(X_test)\n",
        "\n",
        "train_val_f1 = evaluator.evaluate(train_val_predictions)\n",
        "test_f1 = evaluator.evaluate(test_predictions)\n",
        "\n",
        "print(f\"Cross-Validated XGBoost F1 - Train+Val: {train_val_f1:.4f}, Test: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRuNHA94yeYs",
        "outputId": "5ce3f098-7779-4bf0-f8cd-132a7140175a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validated XGBoost F1 - Train+Val: 0.9985, Test: 0.8875\n"
          ]
        }
      ]
    }
  ]
}