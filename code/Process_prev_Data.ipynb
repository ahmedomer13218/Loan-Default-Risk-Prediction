{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4We54BvcLBx9",
        "outputId": "9c6c9047-bec8-4805-af88-e931d6a5ccd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "F-xEsfatLKEf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zZ5duO5WkeMF"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.conf import SparkConf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .appName(\"Process_prev_Data\")\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "xLr2a-YaLOEy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load the data"
      ],
      "metadata": {
        "id": "Jg_guBKEnEJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd6YHQ0Jlnft",
        "outputId": "309f05b5-5203-4275-8fc3-499f8af8bbf5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/drive/MyDrive/Data/previous_application.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btwWk6sjnHb4",
        "outputId": "d3e32b73-1031-4298-ab58-896c7e60a36f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/drive/MyDrive/Data/previous_application.csv.zip: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Data/previous_application.csv.zip\" -d \"/content/previous_application.csv\""
      ],
      "metadata": {
        "id": "G8Wg3M0ana_B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prev = spark.read.csv(\"/content/previous_application.csv/previous_application.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "RnXXtdS6nuRW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Data -> Col null threshold 40% & drop null rows"
      ],
      "metadata": {
        "id": "fZsJvq5BXZNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when, count"
      ],
      "metadata": {
        "id": "2eI97kEkoebI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df_prev.select([count(when(col(c).isNull(), c)).alias(c) for c in df_prev.columns])"
      ],
      "metadata": {
        "id": "PMtwFX3HoSjU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round"
      ],
      "metadata": {
        "id": "ilajaDDqouQz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_percentages = null_counts.select([\n",
        "    (col(c) / df_prev.count() * 100).alias(c) for c in df_prev.columns\n",
        "])\n",
        "null_percentages = null_percentages.select([round(col(c), 2).alias(c) for c in null_percentages.columns])\n"
      ],
      "metadata": {
        "id": "GB33i9RoohhQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with null percentages below 40% and drop them\n",
        "cols_to_drop = [c for c, v in null_percentages.first().asDict().items() if v >= 40]\n",
        "cols_to_drop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEKRpxawo3GC",
        "outputId": "789a80b4-5e66-4d77-d6c5-b6b8819b86e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AMT_DOWN_PAYMENT',\n",
              " 'RATE_DOWN_PAYMENT',\n",
              " 'RATE_INTEREST_PRIMARY',\n",
              " 'RATE_INTEREST_PRIVILEGED',\n",
              " 'NAME_TYPE_SUITE',\n",
              " 'DAYS_FIRST_DRAWING',\n",
              " 'DAYS_FIRST_DUE',\n",
              " 'DAYS_LAST_DUE_1ST_VERSION',\n",
              " 'DAYS_LAST_DUE',\n",
              " 'DAYS_TERMINATION',\n",
              " 'NFLAG_INSURED_ON_APPROVAL']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prev = df_prev.drop(*cols_to_drop)"
      ],
      "metadata": {
        "id": "OoA-rni5pzSu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((df_prev.count(), len(df_prev.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xasXwvGppkOP",
        "outputId": "957bbf6c-4d61-46f6-90e5-065126ca27cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1670214, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import size"
      ],
      "metadata": {
        "id": "yrsPV_8-q_Ct"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the rows with at least one null value\n",
        "df_prev = df_prev.na.drop()"
      ],
      "metadata": {
        "id": "QweaicmgvdM7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((df_prev.count(), len(df_prev.columns)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UfGP9kTYsrK",
        "outputId": "4733fd70-0398-4f6a-c82e-381256584a7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1246320, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate New Features using (prev_features.sh) file"
      ],
      "metadata": {
        "id": "zdp2zHrEXvxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg"
      ],
      "metadata": {
        "id": "KHvGuVjCYqmt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  AMT_ANNUITY -> avg(AMT_ANNUITY)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                     .agg(avg(\"AMT_ANNUITY\").alias(\"PREV_AVG_AMT_ANNUITY\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "G0LxEp69rLtw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  AMT_APPLICATION -> avg(AMT_APPLICATION)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                     .agg(avg(\"AMT_APPLICATION\").alias(\"PREV_AVG_AMT_APPLICATION\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "l0JHc447xRG4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AMT_CREDIT -> avg(AMT_CREDIT)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                    .agg(avg(\"AMT_CREDIT\").alias(\"PREV_AVG_AMT_CREDIT\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "kBJnDprIxukF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AMT_GOODS_PRICE -> avg(AMT_GOODS_PRICE/AMT_APPLICATION)\n",
        "\n",
        "df_prev = df_prev.withColumn(\"GOODS_APP_RATIO\", col(\"AMT_GOODS_PRICE\") / col(\"AMT_APPLICATION\"))\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                   .agg(avg(\"GOODS_APP_RATIO\").alias(\"PREV_AVG_GOODS_APP_RATIO\"))\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "IPZb164YyHfR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DAYS_DECISION -> avg(DAYS_DECISION)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                           .agg(avg(\"DAYS_DECISION\").alias(\"PREV_AVG_DAYS_DECISION\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "yvmgNPGiy9Dp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNT_PAYMENT -> mean(CNT_PAYMENT)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                         .agg(avg(\"CNT_PAYMENT\").alias(\"PREV_AVG_CNT_PAYMENT\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "Bejy3HnXy-Al"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SK_ID_CURR -> count(SK_ID_CURR)\n",
        "prev_filter = df_prev.groupBy('SK_ID_CURR').agg(count(\"*\").alias('PREV_COUNT'))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "Z5cTsQZeY2D7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HOUR_APPR_PROCESS_START -> avg(HOUR_APPR_PROCESS_START)\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "                          .agg(avg(\"HOUR_APPR_PROCESS_START\").alias(\"PREV_AVG_HOUR_APPR_PROCESS_START\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "mJRFoDUrzcfs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## round the values"
      ],
      "metadata": {
        "id": "RiEqhaI4a9LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# round the vlause\n",
        "avg_columns = [\n",
        "    \"PREV_AVG_AMT_ANNUITY\",\n",
        "    \"PREV_AVG_AMT_CREDIT\",\n",
        "    \"PREV_AVG_DAYS_DECISION\",\n",
        "    \"PREV_AVG_GOODS_APP_RATIO\",\n",
        "    \"PREV_AVG_CNT_PAYMENT\",\n",
        "    \"PREV_AVG_HOUR_APPR_PROCESS_START\",\n",
        "    \"PREV_AVG_DAYS_DECISION\",\n",
        "]\n",
        "for col_name in avg_columns:\n",
        "    df_prev = df_prev.withColumn(col_name, round(col(col_name), 2))"
      ],
      "metadata": {
        "id": "f0EFOedA1yco"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_CONTRACT_STATUS -> 2 features (approved , refused)"
      ],
      "metadata": {
        "id": "FU1TNoJr3s6l"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(count(when(col(\"NAME_CONTRACT_STATUS\") == \"Refused\", 1)).alias(\"REFUSED_STATUS_COUNT\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"REFUSED_STATUS_COUNT\": 0})\n"
      ],
      "metadata": {
        "id": "JT4387hU10BA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(count(when(col(\"NAME_CONTRACT_STATUS\") == \"Approved\", 1)).alias(\"APPROVED_STATUS_COUNT\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"APPROVED_STATUS_COUNT\": 0})\n"
      ],
      "metadata": {
        "id": "Ypf3DRA24w4t"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_CONTRACT_TYPE  -> 3 features (all features)"
      ],
      "metadata": {
        "id": "RuYdn3tO56kU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(count(when(col(\"NAME_CONTRACT_TYPE\") == \"Consumer loans\", 1)).alias(\"Consumer loans\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Consumer loans\": 0})"
      ],
      "metadata": {
        "id": "SIPbC0II6qKF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(count(when(col(\"NAME_CONTRACT_TYPE\") == \"Revolving loans\", 1)).alias(\"Revolving loans\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Revolving loans\": 0})"
      ],
      "metadata": {
        "id": "vzVzqaiXQg_s"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(count(when(col(\"NAME_CONTRACT_TYPE\") == \"Cash loans\", 1)).alias(\"Cash loans\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Cash loans\": 0})"
      ],
      "metadata": {
        "id": "1_eLB4a3Qie4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CODE_REJECT_REASON -> 3 features (XAP, HC , Limit)"
      ],
      "metadata": {
        "id": "c7Tuz2pNaaUb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xap_df = df_prev.filter(col(\"CODE_REJECT_REASON\") == \"XAP\") \\\n",
        "                .groupBy(\"SK_ID_CURR\") \\\n",
        "                .agg(count(\"*\").alias(\"XAP\"))\n",
        "\n",
        "df_prev = df_prev.join(xap_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"XAP\": 0})"
      ],
      "metadata": {
        "id": "f-_vZFutaa3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hc_df = df_prev.filter(col(\"CODE_REJECT_REASON\") == \"HC\") \\\n",
        "               .groupBy(\"SK_ID_CURR\") \\\n",
        "               .agg(count(\"*\").alias(\"HC\"))\n",
        "\n",
        "df_prev = df_prev.join(hc_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"HC\": 0})"
      ],
      "metadata": {
        "id": "5B9NdDnPac-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limit_df = df_prev.filter(col(\"CODE_REJECT_REASON\") == \"LIMIT\") \\\n",
        "                  .groupBy(\"SK_ID_CURR\") \\\n",
        "                  .agg(count(\"*\").alias(\"LIMIT\"))\n",
        "\n",
        "df_prev = df_prev.join(limit_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"LIMIT\": 0})"
      ],
      "metadata": {
        "id": "lo0C4xysagrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## drop used features and some unnesesary features (to reduce the overhead)"
      ],
      "metadata": {
        "id": "O67ja3DkbE2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    \"NAME_CONTRACT_TYPE\",\n",
        "    \"AMT_ANNUITY\",\n",
        "    \"AMT_APPLICATION\",\n",
        "    \"AMT_CREDIT\",\n",
        "    \"AMT_GOODS_PRICE\",\n",
        "    \"WEEKDAY_APPR_PROCESS_START\",\n",
        "    \"HOUR_APPR_PROCESS_START\",\n",
        "    \"NAME_CONTRACT_STATUS\",\n",
        "    \"DAYS_DECISION\",\n",
        "    \"NAME_PAYMENT_TYPE\",\n",
        "    \"CODE_REJECT_REASON\",\n",
        "    \"NAME_GOODS_CATEGORY\",\n",
        "    \"NAME_PRODUCT_TYPE\",\n",
        "    \"SELLERPLACE_AREA\",\n",
        "    \"NAME_SELLER_INDUSTRY\",\n",
        "    \"CNT_PAYMENT\",\n",
        "    \"GOODS_APP_RATIO\",\n",
        "]\n",
        "\n",
        "# Drop the specified columns\n",
        "df_prev = df_prev.drop(*columns_to_drop)"
      ],
      "metadata": {
        "id": "d0BMZxgbUC4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_PAYMENT_TYPE -> 1 features (cash payment )"
      ],
      "metadata": {
        "id": "J-e92em47Hye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE : deleted"
      ],
      "metadata": {
        "id": "2Lbd31PkSwZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_CLIENT_TYPE -> 2 features (repeater , refreshed)"
      ],
      "metadata": {
        "id": "10rgxhNt7bqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refreshed_df = df_prev.filter(col(\"NAME_CLIENT_TYPE\") == \"Refreshed\") \\\n",
        "                      .groupBy(\"SK_ID_CURR\") \\\n",
        "                      .agg(count(\"*\").alias(\"Refreshed\"))\n",
        "\n",
        "df_prev = df_prev.join(refreshed_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Refreshed\": 0})"
      ],
      "metadata": {
        "id": "-k5BxKeE_OSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeater_df = df_prev.filter(col(\"NAME_CLIENT_TYPE\") == \"Repeater\") \\\n",
        "                     .groupBy(\"SK_ID_CURR\") \\\n",
        "                     .agg(count(\"*\").alias(\"Repeater\"))\n",
        "\n",
        "df_prev = df_prev.join(repeater_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Repeater\": 0})"
      ],
      "metadata": {
        "id": "9wV_izWT-pZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_PORTFOLIO -> 3 features (POS , Cash , Cards)"
      ],
      "metadata": {
        "id": "iQX5r7gt-pTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_df = df_prev.filter(col(\"NAME_PORTFOLIO\") == \"POS\") \\\n",
        "                .groupBy(\"SK_ID_CURR\") \\\n",
        "                .agg(count(\"*\").alias(\"POS\"))\n",
        "\n",
        "df_prev = df_prev.join(pos_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"POS\": 0})"
      ],
      "metadata": {
        "id": "me2_hAfk_IN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cash_df = df_prev.filter(col(\"NAME_PORTFOLIO\") == \"Cash\") \\\n",
        "                 .groupBy(\"SK_ID_CURR\") \\\n",
        "                 .agg(count(\"*\").alias(\"Cash\"))\n",
        "\n",
        "df_prev = df_prev.join(cash_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Cash\": 0})"
      ],
      "metadata": {
        "id": "R9F0L49_-pP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cards_df = df_prev.filter(col(\"NAME_PORTFOLIO\") == \"Cards\") \\\n",
        "                  .groupBy(\"SK_ID_CURR\") \\\n",
        "                  .agg(count(\"*\").alias(\"Cards\"))\n",
        "\n",
        "df_prev = df_prev.join(cards_df, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.fillna({\"Cards\": 0})"
      ],
      "metadata": {
        "id": "JuCbLEyT-pNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANNEL_TYPE -> top 3 (Credit and cash offices, Country-wide, Stone)"
      ],
      "metadata": {
        "id": "i9QwI0EY-pLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For \"Credit and cash offices\"\n",
        "prev_filter = df_prev.filter(df_prev[\"CHANNEL_TYPE\"] == \"Credit and cash offices\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"Credit and cash offices\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "# For \"Country-wide\"\n",
        "prev_filter = df_prev.filter(df_prev[\"CHANNEL_TYPE\"] == \"Country-wide\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"Country-wide\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "# For \"Stone\"\n",
        "prev_filter = df_prev.filter(df_prev[\"CHANNEL_TYPE\"] == \"Stone\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"Stone\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "df_prev = df_prev.fillna({\"Credit and cash offices\": 0, \"Country-wide\": 0, \"Stone\": 0})"
      ],
      "metadata": {
        "id": "-938ZTfY_H04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRODUCT_COMBINATION -> top 3 (Cash, POS household with interest, POS mobile with interest)"
      ],
      "metadata": {
        "id": "hS3-cFJ2-1tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For \"Cash\"\n",
        "prev_filter = df_prev.filter(df_prev[\"PRODUCT_COMBINATION\"] == \"Cash\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"Cash\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "# For \"POS household with interest\"\n",
        "prev_filter = df_prev.filter(df_prev[\"PRODUCT_COMBINATION\"] == \"POS household with interest\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"POS household with interest\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "# For \"POS mobile with interest\"\n",
        "prev_filter = df_prev.filter(df_prev[\"PRODUCT_COMBINATION\"] == \"POS mobile with interest\") \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"POS mobile with interest\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "\n",
        "df_prev = df_prev.fillna({\n",
        "    \"Cash\": 0,\n",
        "    \"POS household with interest\": 0,\n",
        "    \"POS mobile with interest\": 0\n",
        "})"
      ],
      "metadata": {
        "id": "dtfEtdO__HME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_YIELD_GROUP -> avg(encoded (NAME_YIELD_GROUP))"
      ],
      "metadata": {
        "id": "PJA4YgCXjEQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "ONDIKlyVqWfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {\n",
        "    \"XNA\": 0,\n",
        "    \"low_normal\": 1,\n",
        "    \"middle\": 2,\n",
        "    \"high\": 3\n",
        "}\n",
        "\n",
        "mapping_expr = F.create_map(\n",
        "    *[F.lit(x).cast(\"string\"), F.lit(y).cast(\"int\") for x, y in mapping.items()]\n",
        ")\n",
        "\n",
        "df_prev = df_prev.withColumn(\"NAME_YIELD_GROUP\", mapping_expr[df_prev[\"NAME_YIELD_GROUP\"]])\n",
        "\n",
        "\n",
        "prev_filter = df_prev.groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.mean(\"NAME_YIELD_GROUP\").alias(\"PREV_AVG_NAME_YIELD_GROUP\"))\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "Z2t0318t-1rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FLAG_LAST_APPL_PER_CONTRACT -> sum(0)\n"
      ],
      "metadata": {
        "id": "DRrp_qxwjS2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.filter(df_prev[\"FLAG_LAST_APPL_PER_CONTRACT\"] == 0) \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"ZERO_FLAG_LAST_APPL_PER_CONTRACT\"))\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.withColumn(\"ZERO_FLAG_LAST_APPL_PER_CONTRACT\",\n",
        "                             F.coalesce(df_prev[\"ZERO_FLAG_LAST_APPL_PER_CONTRACT\"], F.lit(0)))"
      ],
      "metadata": {
        "id": "yTVg-0uIjSy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NFLAG_LAST_APPL_IN_DAY-> sum(0)"
      ],
      "metadata": {
        "id": "nPyt6nQrjUtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev.filter(df_prev[\"NFLAG_LAST_APPL_IN_DAY\"] == 0) \\\n",
        "    .groupBy(\"SK_ID_CURR\") \\\n",
        "    .agg(F.count(\"*\").alias(\"ZERO_NFLAG_LAST_APPL_IN_DAY\"))\n",
        "\n",
        "df_prev = df_prev.join(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev = df_prev.withColumn(\"ZERO_NFLAG_LAST_APPL_IN_DAY\",\n",
        "                             F.coalesce(df_prev[\"ZERO_NFLAG_LAST_APPL_IN_DAY\"], F.lit(0)))"
      ],
      "metadata": {
        "id": "7c9kX9BOjUr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NAME_CASH_LOAN_PURPOSE -> XAP, other"
      ],
      "metadata": {
        "id": "b-C4nL8_jaf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_filter = df_prev[df_prev[\"NAME_CASH_LOAN_PURPOSE\"] == \"XAP\"].groupby(\"SK_ID_CURR\").size().reset_index(name=\"XAP_NAME_CASH_LOAN_PURPOSE\")\n",
        "df_prev = df_prev.merge(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev[\"XAP_NAME_CASH_LOAN_PURPOSE\"] = df_prev[\"XAP_NAME_CASH_LOAN_PURPOSE\"].fillna(0)\n",
        "\n",
        "prev_filter = df_prev[(df_prev[\"NAME_CASH_LOAN_PURPOSE\"] != \"XAP\") & (df_prev[\"NAME_CASH_LOAN_PURPOSE\"] != \"XNA\")].groupby(\"SK_ID_CURR\").size().reset_index(name=\"Other_NAME_CASH_LOAN_PURPOSE\")\n",
        "df_prev = df_prev.merge(prev_filter, on=\"SK_ID_CURR\", how=\"left\")\n",
        "df_prev[\"Other_NAME_CASH_LOAN_PURPOSE\"] = df_prev[\"Other_NAME_CASH_LOAN_PURPOSE\"].fillna(0)"
      ],
      "metadata": {
        "id": "vUpZbL6sjacj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop used Col"
      ],
      "metadata": {
        "id": "Vvmcgp87nFYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_columns = [\n",
        "    \"FLAG_LAST_APPL_PER_CONTRACT\",\n",
        "    \"NFLAG_LAST_APPL_IN_DAY\",\n",
        "    \"NAME_CASH_LOAN_PURPOSE\",\n",
        "    \"CODE_REJECT_REASON\",\n",
        "    \"NAME_CLIENT_TYPE\",\n",
        "    \"NAME_PORTFOLIO\",\n",
        "    \"CHANNEL_TYPE\",\n",
        "    \"NAME_YIELD_GROUP\",\n",
        "    \"PRODUCT_COMBINATION\",\n",
        "]\n",
        "df_prev = df_prev.drop(*delete_columns)"
      ],
      "metadata": {
        "id": "-KR1GKc3nHmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop duplicate rows"
      ],
      "metadata": {
        "id": "n-C-bP0jnUAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_prev = df_prev.drop('SK_ID_PREV')\n",
        "df_prev = df_prev.dropDuplicates()"
      ],
      "metadata": {
        "id": "KPuXqEQOnTpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Data"
      ],
      "metadata": {
        "id": "JeaNbUEynijQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "# Define your paths\n",
        "current_dir = '/content/drive/MyDrive'\n",
        "data_relative_path = 'Data'\n",
        "output_dir = os.path.join(current_dir, data_relative_path, \"tmp_output\")\n",
        "\n",
        "def save_csv(df, final_csv_path):\n",
        "    # write df into a temporary folder\n",
        "    df.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(output_dir)\n",
        "\n",
        "    # find the generated part file\n",
        "    part_file = next(Path(output_dir).glob(\"part-*.csv\"))\n",
        "\n",
        "    # move and rename\n",
        "    shutil.move(str(part_file), final_csv_path)\n",
        "\n",
        "    # delete the temporary folder\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "\n",
        "final_csv_path = os.path.join(current_dir, data_relative_path, \"processed_previous_application.csv\")\n",
        "save_csv(df_prev, final_csv_path)"
      ],
      "metadata": {
        "id": "G5mIi1eK3QIV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}